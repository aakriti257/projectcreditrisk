{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9084ecb5-4373-44ab-92d0-e9f6e34c9b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ---------------- Initialize Spark ----------------\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"CreditRisk_BronzeLayer\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())\n",
    "\n",
    "# ---------------- Define Input (Raw Data) ----------------\n",
    "raw_path = \"s3://creditbuc/delta/\"\n",
    "\n",
    "# ---------------- Bronze Catalog Details ----------------\n",
    "bronze_catalog = \"bronze1\"   # Your Glue Catalog\n",
    "bronze_schema = \"credit_data\"   # New schema we will create\n",
    "bronze_table = \"credit_bronze\"\n",
    "\n",
    "# ---------------- Step 1: Read Raw Data ----------------\n",
    "# Assuming your file is CSV (adjust options if JSON/Parquet)\n",
    "df_raw = (spark.read\n",
    "          .option(\"header\", \"true\")\n",
    "          .option(\"inferSchema\", \"true\")\n",
    "          .format('delta').load(raw_path))\n",
    "\n",
    "print(\"✅ Raw Data Loaded\")\n",
    "df_raw.show(5)\n",
    "\n",
    "# ---------------- Step 2: (Optional) Minimal Cleaning ----------------\n",
    "# Bronze layer is usually raw, but let's ensure column names are safe\n",
    "df_bronze = df_raw.toDF(*[c.strip().replace(\" \", \"_\").lower() for c in df_raw.columns])\n",
    "\n",
    "print(\"✅ Columns standardized for Bronze layer\")\n",
    "df_bronze.printSchema()\n",
    "\n",
    "# ---------------- Step 3: Create Schema in Glue Catalog ----------------\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {bronze_catalog}.{bronze_schema}\")\n",
    "\n",
    "print(f\"✅ Schema `{bronze_catalog}.{bronze_schema}` created in Glue Catalog\")\n",
    "\n",
    "# ---------------- Step 4: Write to Bronze Table ----------------\n",
    "(df_bronze.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(f\"{bronze_catalog}.{bronze_schema}.{bronze_table}\"))\n",
    "\n",
    "print(f\"✅ Bronze Table `{bronze_catalog}.{bronze_schema}.{bronze_table}` created\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronzefinal",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
