{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b6f066-68a6-41cb-8f21-e5e283fb8c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "bronze_path = \"s3://creditbuc/credit_risk_dataset.csv\"\n",
    "silver_catalog = \"silver1\"\n",
    "silver_schema = \"credit_data\"\n",
    "silver_table = \"credit_silver\"\n",
    "\n",
    "df_bronze = spark.read.csv(\n",
    "    bronze_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "display(df_bronze)\n",
    "\n",
    "numeric_cols = [\n",
    "    field.name\n",
    "    for field in df_bronze.schema.fields\n",
    "    if str(field.dataType) in [\"IntegerType\", \"DoubleType\", \"LongType\"]\n",
    "]\n",
    "categorical_cols = [\n",
    "    field.name\n",
    "    for field in df_bronze.schema.fields\n",
    "    if str(field.dataType) == \"StringType\"\n",
    "]\n",
    "\n",
    "df_clean = df_bronze\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_value = df_clean.select(F.mean(F.col(col))).collect()[0][0]\n",
    "    if mean_value is not None:\n",
    "        df_clean = df_clean.fillna({col: mean_value})\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_clean = df_clean.fillna({col: \"Unknown\"})\n",
    "\n",
    "df_clean = df_clean.dropDuplicates()\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    df_clean = df_clean.withColumnRenamed(\n",
    "        col,\n",
    "        col.strip().lower().replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "if \"person_age\" in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(\n",
    "        \"person_age\",\n",
    "        F.col(\"person_age\").cast(IntegerType())\n",
    "    )\n",
    "if \"person_income\" in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(\n",
    "        \"person_income\",\n",
    "        F.col(\"person_income\").cast(DoubleType())\n",
    "    )\n",
    "if \"loan_amnt\" in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(\n",
    "        \"loan_amnt\",\n",
    "        F.col(\"loan_amnt\").cast(DoubleType())\n",
    "    )\n",
    "if \"annual_inc\" in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(\n",
    "        \"annual_inc\",\n",
    "        F.col(\"annual_inc\").cast(DoubleType())\n",
    "    )\n",
    "\n",
    "spark.sql(\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS {silver_catalog}.{silver_schema}\"\n",
    ")\n",
    "\n",
    "df_clean.write.format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option(\"overwriteSchema\", \"true\")\\\n",
    "    .partitionBy(\"loan_intent\")\\\n",
    "    .saveAsTable(f\"{silver_catalog}.{silver_schema}.{silver_table}\")\n",
    "\n",
    "df_silver = spark.sql(\n",
    "    f\"SELECT * FROM {silver_catalog}.{silver_schema}.{silver_table} LIMIT 10\"\n",
    ")\n",
    "display(df_silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "634a0798-d9cf-4104-8b15-a3d2ab761348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silverfinal",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
